
# Avatar Agrinho ‚Äî Avatar de Voz em Tempo Real com LiveKit

Este reposit√≥rio entrega a experi√™ncia completa do **Avatar Agrinho**, um **avatar conversacional por voz em tempo real**, capaz de ouvir, interpretar e responder usu√°rios com √°udio sintetizado, mantendo estados visuais sincronizados (ouvindo/falando).

O projeto foi constru√≠do com foco em:

* **Baixa lat√™ncia**
* **Experi√™ncia natural de conversa√ß√£o**
* **Arquitetura desacoplada**
* **Facilidade de customiza√ß√£o de persona**

---

## üéØ Objetivo do Projeto

Criar uma experi√™ncia de **conversa por voz em tempo real** que una:

* Interface visual amig√°vel (avatar animado)
* Processamento de fala e linguagem natural
* Resposta imediata com √°udio
* Possibilidade de expans√£o com **tools externas (MCP)**

O Avatar Agrinho pode ser utilizado em:

* Educa√ß√£o
* Atendimento automatizado
* Demonstra√ß√µes interativas
* Experi√™ncias institucionais ou eventos

---

## üß† Decis√µes T√©cnicas (e por qu√™)

### üé• Por que LiveKit?

O **LiveKit** foi escolhido como base de comunica√ß√£o porque:

* Oferece **WebRTC de baixa lat√™ncia**
* √â ideal para **√°udio em tempo real**
* Possui SDKs maduros para frontend e backend
* Facilita sincroniza√ß√£o de estados entre participantes

Isso √© essencial para uma experi√™ncia de voz **fluida e natural**, sem delays percept√≠veis.

---

### üñ•Ô∏è Por que Next.js no frontend?

O frontend foi constru√≠do em **Next.js** por:

* Excelente integra√ß√£o com React
* Suporte nativo a APIs (`app/api`)
* √ìtima experi√™ncia de desenvolvimento
* Facilidade de deploy (Vercel ou similar)

Al√©m disso, o Next.js permite:

* Separar claramente UI, estado do avatar e gera√ß√£o de tokens
* Renderizar anima√ß√µes e v√≠deos de forma perform√°tica

---

### üêç Por que um agente Python separado?

O **voice_agent** roda como um processo Python independente porque:

* Facilita o uso de bibliotecas de √°udio, VAD e IA
* Permite controle fino do loop de escuta ‚Üí processamento ‚Üí resposta
* Evita acoplamento com o frontend
* Torna o backend reutiliz√°vel (CLI, worker, servi√ßo)

Essa separa√ß√£o segue o princ√≠pio de **responsabilidade √∫nica**.

---

### üß† Por que OpenAI Realtime API?

A **OpenAI Realtime API** foi utilizada para:

* Processar fala e linguagem natural em tempo real
* Reduzir lat√™ncia em compara√ß√£o a chamadas tradicionais
* Permitir respostas cont√≠nuas e interrup√ß√µes

Com isso, o agente consegue:

* Ouvir o usu√°rio enquanto responde
* Interromper a fala se necess√°rio
* Manter uma conversa mais natural

---

### üß© Por que suporte a MCP (opcional)?

O suporte a **MCP (Model Context Protocol)** foi inclu√≠do para:

* Integrar tools externas sem acoplamento forte
* Permitir expans√£o do agente (ex: clima, agenda, sistemas internos)
* Tornar o avatar extens√≠vel para casos reais de neg√≥cio

---

## üß± Arquitetura do Projeto

O projeto √© composto por **dois m√≥dulos independentes**, mas integrados via LiveKit:

* `frontend/`: Interface web e avatar
* `voice_agent/`: Agente de voz e intelig√™ncia

```text
.
|-- frontend/              # Next.js + UI do avatar
|-- voice_agent/           # Agente de voz em Python
|-- start-frontend.sh      # Script para subir o frontend
|-- start-backend.sh       # Script para subir o backend
|-- start-agent.sh         # Agente em sala fixa
|-- start-all.sh           # Frontend + agente
`-- README.md
```

### Por que essa organiza√ß√£o?

* üì¶ Separa√ß√£o clara entre **UI** e **l√≥gica de voz**
* üîÑ Possibilidade de escalar cada parte separadamente
* üß™ Facilita testes e debug
* üîß Permite trocar frontend ou backend sem refatorar tudo

---

## üß∞ Recursos do Projeto

* Conversa√ß√£o por voz em tempo real
* Avatar com estados sincronizados (falando / ouvindo)
* Personas configur√°veis via prompt
* VAD local (Silero) quando dispon√≠vel
* Cancelamento de ru√≠do (BVC)
* Integra√ß√£o opcional com tools via MCP
* Scripts para execu√ß√£o r√°pida

---

## üßë‚Äçüé§ Personas do Agente

O comportamento do avatar √© controlado pela vari√°vel:

```env
ASSISTANT_PROMPT=ASSISTANT
```

Valores dispon√≠veis:

* `ASSISTANT`
* `PROMPT_AGRINHO`
* `VENDEDOR_GENTIL`

üìå Para criar novas personas:

* Edite `voice_agent/prompts.py`
* Defina o tom, vocabul√°rio e comportamento desejado

---

## ‚öôÔ∏è Configura√ß√£o de Ambiente (ESSENCIAL)

> ‚ö†Ô∏è As mesmas credenciais do LiveKit devem ser usadas **no frontend e no backend**

### Frontend ‚Äî `frontend/.env.local`

```dotenv
NEXT_PUBLIC_LIVEKIT_URL=wss://SEU-PROJETO.livekit.cloud
LIVEKIT_API_KEY=APIxxxxxxxx
LIVEKIT_API_SECRET=seu_api_secret_aqui
```

---

### Backend ‚Äî `voice_agent/.env.local`

```dotenv
LIVEKIT_URL=wss://SEU-PROJETO.livekit.cloud
LIVEKIT_API_KEY=APIxxxxxxxx
LIVEKIT_API_SECRET=seu_api_secret_aqui

OPENAI_API_KEY=sk-...

ASSISTANT_PROMPT=ASSISTANT
VOICE=coral
ALLOW_INTERRUPTIONS=true
GREETING=Ola! Eu ja estou te ouvindo. Como posso ajudar?

LOG_LEVEL=INFO
```

üìå **Por que vari√°veis de ambiente?**

* Evitam hardcode de segredos
* Facilitam deploy
* Permitem m√∫ltiplos ambientes

---

## üì¶ Instala√ß√£o

### Frontend

```bash
cd frontend
npm install
```

### Backend

```bash
cd voice_agent
python3 -m venv .venv
source .venv/bin/activate
pip install -r requirements.txt
```

---

## ‚ñ∂Ô∏è Executar Localmente

### 1Ô∏è‚É£ Agente de voz

```bash
cd voice_agent
source .venv/bin/activate
python3 agent.py start
```

### 2Ô∏è‚É£ Frontend

```bash
cd frontend
npm run dev
```

Acesse:
üëâ `http://localhost:3000`
Permita o uso do microfone no navegador.

---

## üöÄ Execu√ß√£o via Scripts

* `./start-frontend.sh`
* `./start-backend.sh`
* `./start-agent.sh`
* `./start-all.sh`

Esses scripts facilitam o uso em ambientes de demonstra√ß√£o e desenvolvimento.

---

## üé® Personaliza√ß√£o

* **V√≠deos do avatar:** `frontend/public/videos/`
* **Voz:** `VOICE=alloy|verse|sage|coral|amber|onyx`
* **Persona:** `ASSISTANT_PROMPT`
* **Tools:** `voice_agent/tools.py`
* **MCP:** vari√°veis `MCP_*`

---

## üß™ Troubleshooting

* **401 Invalid response status**
  Verifique se as credenciais do LiveKit s√£o id√™nticas no frontend e backend.

* **Sem √°udio**
  Confirme `OPENAI_API_KEY` e permiss√£o do microfone.

* **Avatar n√£o muda de estado**
  Valide os v√≠deos e o console do navegador.

---

## üö¢ Deploy (Vis√£o Geral)

* **Frontend:** Vercel ou similar
* **Backend:** servidor Python com HTTPS e WebRTC liberado
* **Requisitos:** firewall liberado para WebRTC

---

## ‚úÖ Checklist R√°pido

* [ ] Criar projeto no LiveKit Cloud
* [ ] Configurar `.env.local` no frontend
* [ ] Configurar `.env.local` no backend
* [ ] Instalar depend√™ncias
* [ ] Rodar agente e frontend
* [ ] Testar microfone e √°udio

---

## üèÅ Conclus√£o

Este projeto demonstra:

* Uso avan√ßado de WebRTC
* Arquitetura desacoplada frontend/backend
* Integra√ß√£o com IA em tempo real
* Design focado em experi√™ncia do usu√°rio
* C√≥digo extens√≠vel e profissional

√â uma base s√≥lida para **produtos conversacionais modernos**, tanto educacionais quanto comerciais.
